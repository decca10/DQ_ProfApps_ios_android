{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popular posts on Hacker News\n",
    "\n",
    "In this project, I am reviewing the Hacker News website.  This site is a popular forum that is similar to Reddit and used by those in technology and startups.  The dataset I am using has been reduced from the [original](https://www.kaggle.com/hacker-news/hacker-news-posts) 300,000 or so rows to approximately 20,000.  This reduction was done by first removing all posts that received no comments, then randomly selecting from the remaining records.  \n",
    "\n",
    "The purpose of this project is to determine popularity of an article based on reader interaction.  That is why we are looking at commented posts.  Further we will examine two types of posts in particular, `Ask HN` and `Show HN`:  \n",
    "- Ask HN: Users submit these posts to ask the Hacker News comunity a specific question.\n",
    "    - Examples:\n",
    "    - *Ask HN: How to improve my personal website?*\n",
    "    - *Ask HN: Am I the only one outraged by Twitter shutting down share counts?*\n",
    "    - *Ask HN: Aby recent changes to CSS that broke mobile?*\n",
    "- Show HN: Users submit these posts to show the community a project, product or generally something interesting.\n",
    "    - Examples:\n",
    "    - *Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'*\n",
    "    - *Show HN: Something pointless I made*\n",
    "    - *Show HN: Shanhu.io, a programming playground powered by e8vm*\n",
    "\n",
    "By examining these types of posts, we hope to answer two questions:\n",
    "1. Do Ask HN or Show HN receive more comments on average?\n",
    "2. Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column titles:  ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "Example of records:  [['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']] \n",
      "\n",
      "Number of records:  20100\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "hn_header = hn[0]\n",
    "hn = hn[1:]\n",
    "print('Column titles: ',hn_header,'\\n')\n",
    "print('Example of records: ',hn[:5],'\\n')\n",
    "print('Number of records: ',len(hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see by the column titles, the attributes are broken down by:\n",
    "    \n",
    "- `id`: The unique identifier from Hacker News for the post\n",
    "- `title`: The title of the post\n",
    "- `url`: The URL that the posts links to, if it the post has a URL\n",
    "- `num_points`: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments`: The number of comments that were made on the post\n",
    "- `author`: The username of the person who submitted the post\n",
    "- `created_at`: The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Ask and Show HN posts\n",
    "\n",
    "Now we will further clean the data to categorize posts into those that contain Ask HN, Show HN or other.  We will do this by creating three lists and extracting the posts to their corresponding category.  One thing we have to account for is that not all posts have formatted capitalization.  Therefore, we will need to use the `string.lower()` type to make sure capitalization is not an issue in categorizing the posts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Show HN:  1744\n",
      "Length of Ask HN:  1162\n",
      "Length of All Others:  17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(\"Length of Show HN: \",len(ask_posts))\n",
    "print(\"Length of Ask HN: \",len(show_posts))\n",
    "print(\"Length of All Others: \",len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the posts issued into lists based on their category, let's analyze the comments section.  We will be looking at how many times an individual post has been commented on by using the `num_comments` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments for Ask HN: 14.04\n"
     ]
    }
   ],
   "source": [
    "#Ask_HN comments averaged\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    total_ask_comments += int(post[4])\n",
    "avg_ask = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print(\"Total comments for Ask HN: {:,.2f}\".format(avg_ask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments for Show HN: 10.32\n"
     ]
    }
   ],
   "source": [
    "#Show_HN comments averaged\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "avg_show = total_show_comments / len(show_posts)\n",
    "print(\"Total comments for Show HN: {:,.2f}\".format(avg_show))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Ask HN posts receive 50% more comments on average than Show HN comments.  This is probably due to the fact that Ask HN posts are asking the community for opinion or help.  And the Hacker News community is active in answering.  Though the community may not be as active in commenting on new products or projects.  \n",
    "\n",
    "Since Ask HN posts receive more posts, we will concentrate on those records for our next analysis.\n",
    "\n",
    "#  Determing what time most posts are commented on.\n",
    "\n",
    "For our next analysis, we want to look at when most posts are commented on, rounded to the nearest hour.  This will help us determine when a post is more likely to be commented on, increasing our chance that an Ask HN post that we create will get more answers.  We will do this by:\n",
    "1. Find the amount of ask posts created during each hour of the day, along with the number of comments those posts received.\n",
    "2. Calculate the average amount of comments ask posts created at each hour of the day receive.\n",
    "\n",
    "We will do that by creating two dictionaries:\n",
    "- `counts_by_hour`: the number of **posts** created during each hour of the day.\n",
    "- `comments_by_hour`: the number of **comments** generated at each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': 251,\n",
       " '13': 1253,\n",
       " '10': 793,\n",
       " '14': 1416,\n",
       " '16': 1814,\n",
       " '23': 543,\n",
       " '12': 687,\n",
       " '17': 1146,\n",
       " '15': 4477,\n",
       " '21': 1745,\n",
       " '20': 1722,\n",
       " '02': 1381,\n",
       " '18': 1439,\n",
       " '03': 421,\n",
       " '05': 464,\n",
       " '19': 1188,\n",
       " '01': 683,\n",
       " '22': 479,\n",
       " '08': 492,\n",
       " '04': 337,\n",
       " '00': 447,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '11': 641}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6],int(row[4])])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for post in result_list:\n",
    "    date = post[0]\n",
    "    no_comm = post[1]\n",
    "    time = dt.datetime.strptime(date, date_format).strftime(\"%H\")\n",
    "    if time not in counts_by_hour:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = no_comm\n",
    "    else:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += no_comm  \n",
    "\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the average number of comments for posts created per each hour of the day as a new list called `avg_by_hour`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hr in comments_by_hour:\n",
    "    avg_by_hour.append([hr,comments_by_hour[hr]/counts_by_hour[hr]])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will format the list to more readable and display the 5 highest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for item in avg_by_hour:\n",
    "    swap_avg_by_hour.append([item[1],item[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Asks Posts Comments:\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "#Sort the values and print the 5 hours with the highest average comments:\n",
    "print(\"Top 5 Hours for Asks Posts Comments:\")\n",
    "\n",
    "for avg,hr in sorted_swap[:5]:\n",
    "    print(\"{}: {:.2f} average comments per post\".format(dt.datetime.strptime(hr,\"%H\").strftime(\"%H:%M\"),avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most average comments of 38.59 were done at 3pm Eastern Standard Time (the time zone indicated in the original [dataset](https://www.kaggle.com/hacker-news/hacker-news-posts/home).  There is about a 60% increase between the highest and second highest average number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing upvotes between Show and Ask HN\n",
    "\n",
    "Next we will add an analysis point to our Show HN and Ask HN datasets.  We will compare the upvotes vs downvotes for votes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upvotes per hour\n",
    "\n",
    "Now we will determine if there are certain hours of the day that a post is given more points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, we analyzed ask posts and show posts to determine which type of post and time receive the most comments on average. Based on our analysis, to maximize the amount of comments a post receives, we'd recommend the post be categorized as an **Ask Post** and created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est).\n",
    "\n",
    "However, it should be noted that the data set we analyzed excluded posts without any comments. Given that, it's more accurate to say that of the posts that received comments, on average:\n",
    "1. **Ask Posts** received more comments AND\n",
    "2. **Ask Posts** created between 15:00 and 16:00 (3:00 pm est - 4:00 pm est) received the most comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
